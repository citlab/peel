system {
    hadoop-1 {
        user = ${system.default.user}
        group = ${system.default.group}
        path {
						isShared = false
            archive.dst = ${app.path.systems}
            config = ${system.hadoop-1.path.home}"/conf"
            log = ${system.hadoop-1.path.home}"/logs"
            input = ${system.hadoop-1.config.core.fs.default.name}"/tmp/input"
            output = ${system.hadoop-1.config.core.fs.default.name}"/tmp/output"
        }
        format = true
        startup {
            max.attempts = ${system.default.startup.max.attempts}
            polling {
                counter = ${system.default.startup.polling.counter}
                interval = ${system.default.startup.polling.interval}
            }
        }
        config {
            # put list of masters
            masters = ${system.default.config.masters}
            # put list of slaves
            slaves = ${system.default.config.slaves}
            # hadoop-env.sh entries
            env {
                JAVA_HOME = ${system.default.config.java.home}
                # directory where process IDs are stored
                HADOOP_PID_DIR = "/tmp/hadoop-1/pid"
            }
            # core-site.xml entries
            core {
                fs.default.name = "hdfs://localhost:9000"
            }
            # hdfs-site.xml entries
            hdfs {
                dfs.replication = 1
                dfs.name.dir = "file:///tmp/hdfs-1/name"
                dfs.data.dir = "file:///tmp/hdfs-1/data"
            }
            # mapred-site.xml entries
            mapred {
                mapred.job.tracker._root_ = "localhost:9001"
                mapred.tasktracker.map.tasks.maximum = ${system.default.config.parallelism.per-node}
                mapred.tasktracker.reduce.tasks.maximum = ${system.default.config.parallelism.per-node}
            }
        }
    }
}